{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자기소개서 데이터 RAW와 label 분리 (다중 분류 임)\n",
    "# 점수 구현은 따로 구현(GPT로 post-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/test_20240708/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0, 1, 2\"  # Set the GPUs 2 and 3 to use\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())\n",
    "\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 186/6011 [00:00<00:03, 1851.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6011/6011 [00:04<00:00, 1294.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                raw_text  \\\n",
      "1      아버지에게서 배운 성실성과 소통 능력\\n\\n평소 꾸준함과 성실함을 강조하시던 부모님...   \n",
      "4      저는 루틴이 가진 강력한 힘을 알고 이용할 줄 압니다 루틴이란 규칙적으로하는 일의 ...   \n",
      "5      코로나 사태로 세계 경제 시장은 더욱 악화되고 있지만 국내 생산거점을 기반으로 내실...   \n",
      "6      저는 석사과정 중 세라믹 섬유용 전구체 합성 분야의 차별화된 연구 역량을 키우기 위...   \n",
      "7      삼성전기는 스마트폰을 비롯한 주요 IT기기 자동차 부품과 네트워크를 제조하는 고객사...   \n",
      "...                                                  ...   \n",
      "16654   빠르게 변화하는 시대에 앞서는 KMAC의 디지털 고숙련 실무인재 양성에 매력을 느...   \n",
      "16655  설득을 무기로 차와 스페셜티 시장 점령\\n\\n식품은 소비자의 가치관을 가장 잘 반영...   \n",
      "16658  저는 기업 니즈를 기반으로 한 영업을 통해 6개 기업을 설득했습니다 대학생 동아리 ...   \n",
      "16659  영업은 고객과 같이 성장하는 직무입니다 고객의 성공이 관계 유지를 가져오기 때문입니...   \n",
      "16660  세계적으로 선진국들은 점차 환경규제를 강화하고 있는 추세이며 유럽연합에서는 이미 상...   \n",
      "\n",
      "                                                   class  \n",
      "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
      "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...  \n",
      "5      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
      "6      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "7      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
      "...                                                  ...  \n",
      "16654  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
      "16655  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
      "16658  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, ...  \n",
      "16659  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
      "16660  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...  \n",
      "\n",
      "[9024 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 파일 불러오고 df에 저장(raw_text 특수문자 제거)\n",
    "\n",
    "file_path = \"/home/najo/NAS/ONLAB/ONLAB_Competency/2024-10-15\"\n",
    "file_name = [f for f in os.listdir(file_path) if f.endswith('.json')]\n",
    "\n",
    "df = pd.DataFrame(columns=['raw_text', 'class'])\n",
    "\n",
    "# 주어진 레이블을 원-핫 인코딩으로 변환하는 함수\n",
    "def multi_label_to_one_hot(labels, num_classes):\n",
    "    one_hot = np.zeros(num_classes, dtype=int)\n",
    "    for label in labels:\n",
    "        if label < num_classes:  # 레이블이 클래스의 총 개수를 넘지 않도록 확인\n",
    "            one_hot[label - 1] = 1  # 인덱스는 0부터 시작하므로 레이블-1로 변환\n",
    "    return one_hot\n",
    "\n",
    "count = 0\n",
    "for i in tqdm(file_name):\n",
    "    with open(os.path.join(file_path, i), 'r', encoding='utf-8') as file:  # Use 'r' mode for reading text files\n",
    "        data = json.load(file)\n",
    "        \n",
    "        for idx in data['anno_text_data']['data']:\n",
    "            classes = []\n",
    "            n_class = list(filter(None, idx['class'].split(\",\")))\n",
    "            for n in n_class:\n",
    "                count += 1\n",
    "                classes.append(int(n))\n",
    "            one_hot_encoded = multi_label_to_one_hot(classes, 21)\n",
    "            df.loc[count, 'raw_text'] = re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\", \"\", idx['raw'])\n",
    "            df.loc[count, 'class'] = one_hot_encoded\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2883296/1908635272.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df.iloc[2000][1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2000][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_text    object\n",
      "class       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# df['class'].value_counts()\n",
    "type(df['class'][1])\n",
    "# df['raw_text'] = df['raw_text'].astype(str)\n",
    "# df['class'] = df['class'].astype(float)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/test_20240708/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# KLUE-RoBERTa 모델과 토크나이저 로드\n",
    "model_name = \"klue/roberta-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=21, problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index, 0]\n",
    "        label = self.data.iloc[index, 1]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "max_len = 128\n",
    "train_dataset = CustomDataset(df, tokenizer, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0,  4096,  2170,  2318,  2112,  8174,  7658,  2047,  2145,  4740,\n",
       "          4053,  5076,  5160,  2530,  2145,  7658,  2530,  2069,  3986,  2205,\n",
       "          2067,  2414,  4267,  2098,  2073,  1545,  2116,  2227,  2540,  2444,\n",
       "          3804,  2052,   859,  2015,  2138,  4156,  3011,  2219,  3606,  4096,\n",
       "          2678,  2112,  2259,  1535,  2170,  2318,  4408,  7796,  2069,  4735,\n",
       "          2205,  3011,  2088,  1535,  2259,  4885,  4622,    25, 18458,  3797,\n",
       "          5868,  7193,  1537,  3610,  4709,  4408,  3815,  2069,  1889,  2507,\n",
       "          2219,  3606,  8345,  3644,  1535,  2259,  7658,  2047,  2145,  4740,\n",
       "          2526,  2069, 12535,  1295,  1513,  2359,  2219,  3606,     2,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/test_20240708/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m# 손실이 이전 손실보다 작으면 모델 저장\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(logits, labels)\n\u001b[1;32m     25\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n",
      "File \u001b[0;32m~/.conda/envs/test_20240708/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/test_20240708/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/test_20240708/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "# BCEWithLogitsLoss 설정 (multi-label classification용)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].float().to(device)  # 레이블을 float형으로 변환 (필수)\n",
    "\n",
    "        # 모델의 출력에서 loss 추출\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # loss 계산\n",
    "        loss = loss_fn(logits, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 모델 저장 함수 (DataParallel 지원)\n",
    "def save_model(model, optimizer, epoch, loss, file_name):\n",
    "    save_path = f\"/home/najo/NAS/ONLAB/ONLAB_Competency/Saved_model/{file_name}.pth\"\n",
    "    \n",
    "    # DataParallel로 감싸져 있는 모델을 저장할 때는 model.module로 접근\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model_to_save = model.module\n",
    "    else:\n",
    "        model_to_save = model\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_to_save.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, save_path)\n",
    "    \n",
    "    print(f\"Model saved as {save_path}\")\n",
    "\n",
    "# GPU 설정\n",
    "model = model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 학습 루프\n",
    "epochs = 100\n",
    "best_loss = float('inf')  # 최소 손실을 추적하기 위한 변수\n",
    "for epoch in range(epochs):\n",
    "    if epoch % 5 == 0:\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {train_loss}\")\n",
    "\n",
    "        # 손실이 이전 손실보다 작으면 모델 저장\n",
    "        if train_loss < best_loss:\n",
    "            best_loss = train_loss\n",
    "            # 손실 값을 파일명에 포함, 소수점 5자리까지 사용\n",
    "            file_name = f\"model_loss_{best_loss:.5f}\"\n",
    "            save_model(model, optimizer, epoch, best_loss, file_name)\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found: model_loss_0.01375.pth with loss 0.01375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2883296/3691781199.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /home/najo/NAS/ONLAB/ONLAB_Competency/Saved_model/model_loss_0.01375.pth, Epoch: 95, Loss: 0.01375\n",
      "Validation Loss: 0.0106, F1-Score: 0.9341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/najo/.conda/envs/test_20240708/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# BCEWithLogitsLoss 설정\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 평가 함수 (multi-label classification에 맞게 수정)\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].float().to(device)  # 레이블을 float으로 변환\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # 시그모이드 적용하여 각 클래스에 대한 확률을 계산\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            # 특정 기준(예: 0.5)을 넘으면 1로 예측\n",
    "            preds = (probs > 0.5).float()\n",
    "\n",
    "            # 손실 계산\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_predictions.append(preds.cpu().numpy())\n",
    "            all_true_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # 평가 지표 계산 (여기서는 F1-Score를 사용)\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_true_labels = np.vstack(all_true_labels)\n",
    "    \n",
    "    f1 = f1_score(all_true_labels, all_predictions, average='macro')  # 매크로 F1 스코어 사용\n",
    "    \n",
    "    return total_loss / len(data_loader), f1\n",
    "\n",
    "# 저장된 모델 불러오기 함수\n",
    "def load_best_model(model, optimizer, device, file_path):\n",
    "    checkpoint = torch.load(file_path)\n",
    "    \n",
    "    # DataParallel로 감싸진 경우에도 model.module로 저장되었는지 확인\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model.module.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    \n",
    "    model = model.to(device)  # 모델을 다시 GPU로 보냄\n",
    "    print(f\"Loaded model from {file_path}, Epoch: {epoch}, Loss: {loss:.5f}\")\n",
    "    \n",
    "    return model, optimizer\n",
    "\n",
    "# 저장된 모델 파일 중에서 가장 작은 손실 값을 가진 모델 파일을 찾는 함수\n",
    "def find_best_model_file(model_dir):\n",
    "    best_loss = float('inf')\n",
    "    best_model_file = None\n",
    "    \n",
    "    # 모델 파일명을 탐색하고, 손실값이 포함된 파일명을 파싱하여 최소 손실값을 찾음\n",
    "    for file_name in os.listdir(model_dir):\n",
    "        if file_name.endswith(\".pth\"):\n",
    "            # 파일명에서 손실 값을 추출 (예: model_loss_0.12345.pth에서 0.12345 추출)\n",
    "            match = re.search(r'model_loss_([\\d.]+)\\.pth', file_name)\n",
    "            if match:\n",
    "                loss = float(match.group(1))\n",
    "                if loss < best_loss:\n",
    "                    best_loss = loss\n",
    "                    best_model_file = file_name\n",
    "    \n",
    "    if best_model_file:\n",
    "        print(f\"Best model found: {best_model_file} with loss {best_loss:.5f}\")\n",
    "    else:\n",
    "        print(\"No valid model files found.\")\n",
    "    \n",
    "    return best_model_file\n",
    "\n",
    "# 저장된 최적의 모델 불러오기 및 평가 함수는 그대로\n",
    "def evaluate_best_model(model, optimizer, data_loader, device, model_dir):\n",
    "    best_model_file = find_best_model_file(model_dir)\n",
    "    \n",
    "    if best_model_file:\n",
    "        file_path = os.path.join(model_dir, best_model_file)\n",
    "        model, optimizer = load_best_model(model, optimizer, device, file_path)\n",
    "        \n",
    "        # 모델 평가\n",
    "        val_loss, val_f1 = eval_model(model, data_loader, device)\n",
    "        print(f'Validation Loss: {val_loss:.4f}, F1-Score: {val_f1:.4f}')\n",
    "    else:\n",
    "        print(\"No model file to evaluate.\")\n",
    "\n",
    "# 검증 데이터 로더로 변경하는 것이 일반적\n",
    "best_model_path = \"/home/najo/NAS/ONLAB/ONLAB_Competency/Saved_model\"\n",
    "\n",
    "# 학습 후 검증 데이터 평가\n",
    "evaluate_best_model(model, optimizer, train_loader, device, best_model_path)  # 평가할 때는 val_loader 사용을 권장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found: model_loss_0.01375.pth with loss 0.01375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2883296/3691781199.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /home/najo/NAS/ONLAB/ONLAB_Competency/Saved_model/model_loss_0.01375.pth, Epoch: 95, Loss: 0.01375\n",
      "Predicted Class: [[0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 새로운 텍스트에 대해 예측 함수 (저장된 모델을 불러와 예측)\n",
    "def predict(text, model, tokenizer, max_len, device, model_dir):\n",
    "    # 가장 낮은 loss 값을 가진 모델 파일 찾기\n",
    "    best_model_file = find_best_model_file(model_dir)\n",
    "    \n",
    "    if best_model_file is None:\n",
    "        raise ValueError(\"No valid model file found.\")\n",
    "    \n",
    "    model_path = os.path.join(model_dir, best_model_file)\n",
    "    \n",
    "    # 모델을 저장된 상태로 불러오기\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # 옵티마이저 임시 생성\n",
    "    model, optimizer = load_best_model(model, optimizer, device, model_path)\n",
    "\n",
    "    # 입력 텍스트를 토크나이저로 인코딩\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # 멀티 라벨 분류에서는 시그모이드 함수 적용 후, 임계값 기준으로 0/1 결정\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()  # 0.5 이상의 확률을 가진 경우 1로 예측\n",
    "    \n",
    "    return preds.cpu().numpy()  # 예측된 결과를 numpy 배열로 변환\n",
    "\n",
    "# 예측 사용 예시\n",
    "sample_text1 = \"기재한 역량 및 기술 중 한 가지 이상을 선택하고 그러한 역량 및 기술을 적극적으로 활용했던 경험 또는 이를 습득하기까지의 과정을 기술하여 주십시오.\\n\\n\\\"업무 추진력의 바탕 : 세밀한 기획\\\"\\n\\n인문학 교실을 기획하고 운영하는 프로그램 당시, 일정이 바뀌어 인턴십이 겹치고 하차 인원이 생겨 인력, 시간이 부족했고 이를 극복하기 위해 다음과 같이 행동했습니다.\\n\\n첫째, 진행된 과제 상황을 파악하고 앞으로 해야 할 일과 사용 가능한 시간을 리스트로 만들었습니다. 그리고 우선순위에 따라 시간을 배분한 후 추가적으로 필요한 시간을 확인했습니다.\\n\\n둘째, 불필요한 업무 프로세스를 개선해 부족한 시간을 확보했습니다. 반복되는 자료와 문서는 형상관리를 이용해 재사용할 수 있도록 했습니다.\\n\\n셋째, 또 다른 일정 변동에 대비해 강의자를 2인 1조로 구성했고, 수업을 하는 동안 강의록을 작성해 최종 보고서 작성 시간도 줄일 수 있었습니다.\"\n",
    "sample_text2 = \"\\\"사람을 향하는 기술\\\"\\n삼성전자는 항상 혁신을 이뤄왔으며 우리나라를 대표할 뿐만 아니라 글로벌 기업으로 인정받고 있습니다. 이러한 입지는 결국 삼성전자가 많은 사람에게 선택받았다는 방증이기도 합니다. 즉, 사용자를 위한 제품을 꾸준히 개발하고 사용자를 위한 방향으로 기술을 발전시켜나가고 있다고 생각했습니다.\\n\\n저도 사람을 향하는 서비스를 만드는 개발자가 되고 싶습니다. 프로젝트를 하면서 가장 어려웠던 부분은 항상 주제를 정하는 것이었습니다. 그동안은 뭘 만들까가 아니라 어떤 기술을 이용해서 만들까에 초점을 맞췄기 때문에 이러한 어려움이 있었습니다. 하지만 졸업 프로젝트를 할 때는 처음으로 사용자 관점에서 생각하여 프로젝트를 진행하게 되었습니다.\\n사용자는 다양하고 그들의 필요한 부분도 다양할 것입니다. 하지만 결국 필요한 부분이라면, 놓치지 않고 그 필요를 충족시키는 서비스를 개발하고 싶습니다. 더 나아가 약자도 소외되지 않는, 기술로 인해 소외되는 사람이 없는 그런 서비스를 만들어가고 싶습니다.\"\n",
    "sample_text3 = \"**즐거움과 열정을 갖고 배울 수 있는 개발자**\\n\\n대학생 때 자바를 접한 후 처음에는 취업을 위해 여러 활동을 해 보았습니다.\\n그러던 중 그동안 배운 내용들을 토대로 코드를 한 땀 한 땀 짜면서 프로젝트를 진행해 보았는데, 원하는 결과물을 하나씩 만들 수 있다는 것이 인상 깊었습니다.\\n이후로 강의를 듣거나 지식을 쌓은 후 다시 코드를 수정하면서 같은 결과여도 다른 방식이 있을 수 있고, 그 코드를 잘 만들어 내는 것의 중요성을 알았습니다.\\n그렇게 하나의 결과물을 만들기 위한 많은 길이 존재하며, 어떤 식으로 구현하는지에 따라 성능을 향상시킬 수 있다는 것을 알게 된 후 계속해서 이를 배워나가 최고의 실력을 갖고 싶다는 마음을 가지게 되었습니다.\\n\\n그리고 운이 좋게도 이런 마음가짐을 갖게 되자, 개발 자체가 재미있어졌고 단순히 공부나 일이 아닌, 취미로서 즐길 수 있게 되었습니다.\\n좋아하는 것에 있어서 잘 하고 싶고, 완벽해지고 싶어 하는 성미이기에 개발에 취미를 갖게 된 이후 지금까지 끊임없이 노력할 수 있었습니다.\\n앞으로도 개발자로서 제가 가진 열정이라는 원동력을 놓치지 않고, 더욱 발전해 나가겠습니다.\"\n",
    "# label \"5,11,10,17,20\"\n",
    "re_sample_text = re.sub(r\"[^\\uAC00-\\uD7A30-9a-zA-Z\\s]\", \"\", sample_text3)\n",
    "\n",
    "# 저장된 모델 경로를 사용해 예측\n",
    "predicted_class = predict(re_sample_text, model, tokenizer, max_len, device, best_model_path)\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mention counts (sorted by count):\n",
      "Class 6: 2024\n",
      "Class 11: 1867\n",
      "Class 14: 1568\n",
      "Class 17: 1398\n",
      "Class 12: 1008\n",
      "Class 5: 1000\n",
      "Class 15: 998\n",
      "Class 16: 990\n",
      "Class 7: 934\n",
      "Class 13: 784\n",
      "Class 10: 761\n",
      "Class 2: 652\n",
      "Class 3: 579\n",
      "Class 4: 494\n",
      "Class 1: 370\n",
      "Class 20: 345\n",
      "Class 18: 218\n",
      "Class 8: 206\n",
      "Class 9: 201\n",
      "Class 19: 134\n",
      "Class 21: 129\n",
      "Total number of class mentions: 16660\n"
     ]
    }
   ],
   "source": [
    "index_count = []\n",
    "classes = []\n",
    "\n",
    "# List of classes to exclude\n",
    "exclude_classes = {' ', ''}  # Use a set for faster lookups\n",
    "\n",
    "# Assuming file_name is a list of filenames and file_path is the directory where these files are stored\n",
    "for i in file_name:\n",
    "    with open(os.path.join(file_path, i), 'r', encoding='utf-8') as file:  # Use 'r' mode for reading text files\n",
    "        data = json.load(file)\n",
    "        \n",
    "        # Step 1: Extract class mentions\n",
    "        for entry in data['anno_text_data']['data']:\n",
    "            # Filter out classes that should be excluded\n",
    "            classes.extend([cls for cls in entry['class'].split(',') if cls not in exclude_classes])\n",
    "\n",
    "# Step 2: Count occurrences of each class\n",
    "class_counts = Counter(classes)\n",
    "\n",
    "# Step 3: Calculate the total number of class mentions\n",
    "total_count = sum(class_counts.values())\n",
    "\n",
    "# Step 4: Display the results sorted by count in descending order\n",
    "print(\"Class mention counts (sorted by count):\")\n",
    "for class_id, count in sorted(class_counts.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"Class {class_id}: {count}\")\n",
    "\n",
    "# Print the total sum of all counts\n",
    "print(f\"Total number of class mentions: {total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort by count in descending order\n",
    "sorted_class_counts = sorted(class_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Extract class IDs and counts for plotting\n",
    "class_ids, counts = zip(*sorted_class_counts)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(class_ids, counts, color='skyblue')\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Mention Counts (sorted by count)')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name  Index\n",
      "0            창의력을 가진      1\n",
      "1         유연한 사고를 가진      2\n",
      "2   데이터 기반의 의사결정을 하는      3\n",
      "3       다양한 의견을 수렴하는      4\n",
      "4        문제해결능력이 뛰어난      5\n",
      "5    탄탄한 의사소통 능력을 가진      6\n",
      "6       선한 영향력을 행사하는      7\n",
      "7          다양성을 존중하는      8\n",
      "8          신뢰를 주는 리더      9\n",
      "9            적응력이 높은     10\n",
      "10     지속적인 성장을 추구하는     11\n",
      "11          비전을 제시하는     12\n",
      "12     고도의 자기주도성을 가진     13\n",
      "13      비즈니스 마인드를 갖춘     14\n",
      "14       고도의 책임감을 가진     15\n",
      "15              적극적인     16\n",
      "16   목표를 달성하는 능력을 갖춘     17\n",
      "17    자원을 효율적으로 활용하는     18\n",
      "18     신속한 의사결정을 내리는     19\n",
      "19       긍정적인 태도를 갖춘     20\n",
      "20  위기 상황에서도 안정감을 주는     21\n"
     ]
    }
   ],
   "source": [
    "index  = pd.read_excel(\"/home/najo/NAS/ONLAB/ONLAB_Competency/keyword-index.xlsx\")\n",
    "\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_20240708",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
